{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業\n",
    "礙於不是所有同學都有 GPU ，這邊的範例使用的是簡化版本的 ResNet，確保所有同學都能夠順利訓練!\n",
    "\n",
    "\n",
    "最後一天的作業請閱讀這篇非常詳盡的[文章](https://blog.gtwang.org/programming/keras-resnet-50-pre-trained-model-build-dogs-cats-image-classification-system/)，基本上已經涵蓋了所有訓練　CNN 常用的技巧，請使用所有學過的訓練技巧，盡可能地提高 Cifar-10 的 test data 準確率，截圖你最佳的結果並上傳來完成最後一次的作業吧!\n",
    "\n",
    "另外這些技巧在 Kaggle 上也會被許多人使用，更有人會開發一些新的技巧，例如使把預訓練在 ImageNet 上的模型當成 feature extractor 後，再拿擷取出的特徵重新訓練新的模型，這些技巧再進階的課程我們會在提到，有興趣的同學也可以[參考](https://www.kaggle.com/insaff/img-feature-extraction-with-pretrained-resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.python.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "# from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 若 GPU 記憶體不足，可調降 batch size 或凍結更多層網路\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# 凍結網路層數\n",
    "# FREEZE_LAYERS = 2\n",
    "\n",
    "# Epoch 數\n",
    "NUM_EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# 讀取資料集並作前處理\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = preprocess_input(x_train) \n",
    "x_test = preprocess_input(x_test)\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 38, 38, 3)    0           input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 16, 16, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 16, 16, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 16, 16, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 18, 18, 64)   0           activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 64)     0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 8, 8, 64)     4160        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 8, 8, 64)     0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 8, 8, 64)     0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 8, 8, 256)    16640       max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 8, 8, 256)    1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_80 (Add)                    (None, 8, 8, 256)    0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 8, 8, 256)    0           add_80[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 8, 8, 64)     0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 8, 8, 64)     0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_81 (Add)                    (None, 8, 8, 256)    0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 8, 8, 256)    0           add_81[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 8, 8, 64)     16448       activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_252 (Activation)     (None, 8, 8, 64)     0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 8, 8, 64)     36928       activation_252[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 8, 8, 64)     256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_253 (Activation)     (None, 8, 8, 64)     0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 8, 8, 256)    16640       activation_253[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 8, 8, 256)    1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_82 (Add)                    (None, 8, 8, 256)    0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_254 (Activation)     (None, 8, 8, 256)    0           add_82[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 4, 4, 128)    32896       activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_255 (Activation)     (None, 4, 4, 128)    0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_255[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_256 (Activation)     (None, 4, 4, 128)    0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_256[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 4, 4, 512)    131584      activation_254[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 4, 4, 512)    2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_83 (Add)                    (None, 4, 4, 512)    0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_257 (Activation)     (None, 4, 4, 512)    0           add_83[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_258 (Activation)     (None, 4, 4, 128)    0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_258[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_259 (Activation)     (None, 4, 4, 128)    0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_259[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_84 (Add)                    (None, 4, 4, 512)    0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_257[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_260 (Activation)     (None, 4, 4, 512)    0           add_84[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_261 (Activation)     (None, 4, 4, 128)    0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_261[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_262 (Activation)     (None, 4, 4, 128)    0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_262[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_85 (Add)                    (None, 4, 4, 512)    0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_260[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_263 (Activation)     (None, 4, 4, 512)    0           add_85[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 4, 4, 128)    65664       activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_264 (Activation)     (None, 4, 4, 128)    0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 4, 4, 128)    147584      activation_264[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 4, 4, 128)    512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_265 (Activation)     (None, 4, 4, 128)    0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 4, 4, 512)    66048       activation_265[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 4, 4, 512)    2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_86 (Add)                    (None, 4, 4, 512)    0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_263[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_266 (Activation)     (None, 4, 4, 512)    0           add_86[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 2, 2, 256)    131328      activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_267 (Activation)     (None, 2, 2, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_267[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_268 (Activation)     (None, 2, 2, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_268[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 2, 2, 1024)   525312      activation_266[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 2, 2, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_87 (Add)                    (None, 2, 2, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_269 (Activation)     (None, 2, 2, 1024)   0           add_87[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_270 (Activation)     (None, 2, 2, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_270[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_271 (Activation)     (None, 2, 2, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_271[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_88 (Add)                    (None, 2, 2, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_269[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_272 (Activation)     (None, 2, 2, 1024)   0           add_88[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_273 (Activation)     (None, 2, 2, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_273[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_274 (Activation)     (None, 2, 2, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_274[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_89 (Add)                    (None, 2, 2, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_272[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_275 (Activation)     (None, 2, 2, 1024)   0           add_89[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_276 (Activation)     (None, 2, 2, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_276[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_277 (Activation)     (None, 2, 2, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_277[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_90 (Add)                    (None, 2, 2, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_275[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_278 (Activation)     (None, 2, 2, 1024)   0           add_90[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 2, 2, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 2, 2, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_91 (Add)                    (None, 2, 2, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_278[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 2, 2, 1024)   0           add_91[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 2, 2, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 2, 2, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_92 (Add)                    (None, 2, 2, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 2, 2, 1024)   0           add_92[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 1, 1, 512)    524800      activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 1, 1, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 1, 1, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 1, 1, 2048)   2099200     activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 1, 1, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_93 (Add)                    (None, 1, 1, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 1, 1, 2048)   0           add_93[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 1, 1, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 1, 1, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_94 (Add)                    (None, 1, 1, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 1, 1, 2048)   0           add_94[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 1, 1, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 1, 1, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_95 (Add)                    (None, 1, 1, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 1, 1, 2048)   0           add_95[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 2048)         0           activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1024)         2098176     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Dense)                 (None, 10)           10250       dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 25,696,138\n",
      "Trainable params: 2,108,426\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 以訓練好的 ResNet50 為基礎來建立模型，\n",
    "# 捨棄 ResNet50 頂層的 fully connected layers\n",
    "\n",
    "\n",
    "base_model = ResNet50(include_top=False, weights='imagenet',input_shape=(32, 32,3), pooling = 'avg')\n",
    "\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = base_model.output\n",
    "x = Flatten(name='flatten')(x)\n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "\n",
    "# 增加 Dense layer，以 softmax 產生個類別的機率值\n",
    "output_layer = Dense(10, activation='softmax', name='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 ImageDataGenerator，並指定我們要做資料增強的數值範圍\n",
    "data_generator = ImageDataGenerator(\n",
    "                                   rotation_range=30,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   channel_shift_range=10,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "195/195 [==============================] - 49s 249ms/step - loss: 2.2111 - acc: 0.2717 - val_loss: 2.5613 - val_acc: 0.4093\n",
      "Epoch 2/100\n",
      "195/195 [==============================] - 39s 202ms/step - loss: 1.8355 - acc: 0.3872 - val_loss: 2.4397 - val_acc: 0.4254\n",
      "Epoch 3/100\n",
      "195/195 [==============================] - 39s 202ms/step - loss: 1.7389 - acc: 0.4068 - val_loss: 2.3701 - val_acc: 0.4299\n",
      "Epoch 4/100\n",
      "195/195 [==============================] - 39s 202ms/step - loss: 1.6784 - acc: 0.4255 - val_loss: 2.2664 - val_acc: 0.4361\n",
      "Epoch 5/100\n",
      "195/195 [==============================] - 39s 202ms/step - loss: 1.6478 - acc: 0.4347 - val_loss: 2.3203 - val_acc: 0.4313\n",
      "Epoch 6/100\n",
      "195/195 [==============================] - 41s 211ms/step - loss: 1.6199 - acc: 0.4432 - val_loss: 2.2847 - val_acc: 0.4335\n",
      "Epoch 7/100\n",
      "195/195 [==============================] - 40s 204ms/step - loss: 1.5944 - acc: 0.4508 - val_loss: 2.2372 - val_acc: 0.4407\n",
      "Epoch 8/100\n",
      "195/195 [==============================] - 40s 206ms/step - loss: 1.5750 - acc: 0.4572 - val_loss: 2.2281 - val_acc: 0.4442\n",
      "Epoch 9/100\n",
      "195/195 [==============================] - 40s 205ms/step - loss: 1.5606 - acc: 0.4595 - val_loss: 2.2919 - val_acc: 0.4374\n",
      "Epoch 10/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.5507 - acc: 0.4652 - val_loss: 2.2461 - val_acc: 0.4380\n",
      "Epoch 11/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.5416 - acc: 0.4677 - val_loss: 2.2320 - val_acc: 0.4397\n",
      "Epoch 12/100\n",
      "195/195 [==============================] - 40s 205ms/step - loss: 1.5311 - acc: 0.4713 - val_loss: 2.2614 - val_acc: 0.4348\n",
      "Epoch 13/100\n",
      "195/195 [==============================] - 40s 204ms/step - loss: 1.5172 - acc: 0.4740 - val_loss: 2.2233 - val_acc: 0.4431\n",
      "Epoch 14/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.5093 - acc: 0.4751 - val_loss: 2.2323 - val_acc: 0.4420\n",
      "Epoch 15/100\n",
      "195/195 [==============================] - 40s 205ms/step - loss: 1.5018 - acc: 0.4770 - val_loss: 2.1778 - val_acc: 0.4488\n",
      "Epoch 16/100\n",
      "195/195 [==============================] - 41s 209ms/step - loss: 1.5009 - acc: 0.4799 - val_loss: 2.1708 - val_acc: 0.4521\n",
      "Epoch 17/100\n",
      "195/195 [==============================] - 40s 206ms/step - loss: 1.4896 - acc: 0.4841 - val_loss: 2.1700 - val_acc: 0.4542\n",
      "Epoch 18/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.4921 - acc: 0.4815 - val_loss: 2.2253 - val_acc: 0.4456\n",
      "Epoch 19/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.4788 - acc: 0.4845 - val_loss: 2.2213 - val_acc: 0.4460\n",
      "Epoch 20/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.4878 - acc: 0.4826 - val_loss: 2.1878 - val_acc: 0.4464\n",
      "Epoch 21/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.4734 - acc: 0.4877 - val_loss: 2.1499 - val_acc: 0.4505\n",
      "Epoch 22/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.4710 - acc: 0.4886 - val_loss: 2.1167 - val_acc: 0.4575\n",
      "Epoch 23/100\n",
      "195/195 [==============================] - 41s 208ms/step - loss: 1.4600 - acc: 0.4924 - val_loss: 2.1433 - val_acc: 0.4523\n",
      "Epoch 24/100\n",
      "195/195 [==============================] - 40s 205ms/step - loss: 1.4640 - acc: 0.4914 - val_loss: 2.1355 - val_acc: 0.4496\n",
      "Epoch 25/100\n",
      "195/195 [==============================] - 41s 209ms/step - loss: 1.4542 - acc: 0.4939 - val_loss: 2.1311 - val_acc: 0.4529\n",
      "Epoch 26/100\n",
      "195/195 [==============================] - 41s 209ms/step - loss: 1.4446 - acc: 0.4976 - val_loss: 2.1484 - val_acc: 0.4513\n",
      "Epoch 27/100\n",
      "195/195 [==============================] - 40s 205ms/step - loss: 1.4481 - acc: 0.4971 - val_loss: 2.1688 - val_acc: 0.4427\n",
      "Epoch 28/100\n",
      "195/195 [==============================] - 42s 216ms/step - loss: 1.4411 - acc: 0.4998 - val_loss: 2.1495 - val_acc: 0.4466\n",
      "Epoch 29/100\n",
      "195/195 [==============================] - 40s 206ms/step - loss: 1.4454 - acc: 0.4969 - val_loss: 2.1636 - val_acc: 0.4451\n",
      "Epoch 30/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.4398 - acc: 0.4980 - val_loss: 2.1382 - val_acc: 0.4502\n",
      "Epoch 31/100\n",
      "195/195 [==============================] - 41s 208ms/step - loss: 1.4358 - acc: 0.4996 - val_loss: 2.1348 - val_acc: 0.4499\n",
      "Epoch 32/100\n",
      "195/195 [==============================] - 40s 206ms/step - loss: 1.4352 - acc: 0.5014 - val_loss: 2.0991 - val_acc: 0.4544\n",
      "Epoch 33/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.4264 - acc: 0.5060 - val_loss: 2.1443 - val_acc: 0.4509\n",
      "Epoch 34/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.4278 - acc: 0.5000 - val_loss: 2.1918 - val_acc: 0.4448\n",
      "Epoch 35/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.4225 - acc: 0.5046 - val_loss: 2.1382 - val_acc: 0.4512\n",
      "Epoch 36/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.4292 - acc: 0.5029 - val_loss: 2.0961 - val_acc: 0.4545\n",
      "Epoch 37/100\n",
      "195/195 [==============================] - 41s 208ms/step - loss: 1.4185 - acc: 0.5063 - val_loss: 2.1010 - val_acc: 0.4541\n",
      "Epoch 38/100\n",
      "195/195 [==============================] - 40s 206ms/step - loss: 1.4215 - acc: 0.5026 - val_loss: 2.1166 - val_acc: 0.4545\n",
      "Epoch 39/100\n",
      "195/195 [==============================] - 41s 209ms/step - loss: 1.4204 - acc: 0.5064 - val_loss: 2.1135 - val_acc: 0.4538\n",
      "Epoch 40/100\n",
      "195/195 [==============================] - 41s 208ms/step - loss: 1.4109 - acc: 0.5053 - val_loss: 2.1147 - val_acc: 0.4558\n",
      "Epoch 41/100\n",
      "195/195 [==============================] - 41s 212ms/step - loss: 1.4137 - acc: 0.5072 - val_loss: 2.1164 - val_acc: 0.4541\n",
      "Epoch 42/100\n",
      "195/195 [==============================] - 41s 212ms/step - loss: 1.4112 - acc: 0.5045 - val_loss: 2.1222 - val_acc: 0.4534\n",
      "Epoch 43/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.4035 - acc: 0.5096 - val_loss: 2.0964 - val_acc: 0.4563\n",
      "Epoch 44/100\n",
      "195/195 [==============================] - 41s 211ms/step - loss: 1.4079 - acc: 0.5121 - val_loss: 2.1132 - val_acc: 0.4543\n",
      "Epoch 45/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.4006 - acc: 0.5124 - val_loss: 2.0958 - val_acc: 0.4574\n",
      "Epoch 46/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.4074 - acc: 0.5109 - val_loss: 2.1144 - val_acc: 0.4534\n",
      "Epoch 47/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.3970 - acc: 0.5096 - val_loss: 2.1108 - val_acc: 0.4520\n",
      "Epoch 48/100\n",
      "195/195 [==============================] - 42s 213ms/step - loss: 1.4055 - acc: 0.5088 - val_loss: 2.0949 - val_acc: 0.4556\n",
      "Epoch 49/100\n",
      "195/195 [==============================] - 41s 209ms/step - loss: 1.4029 - acc: 0.5102 - val_loss: 2.0822 - val_acc: 0.4561\n",
      "Epoch 50/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.3951 - acc: 0.5152 - val_loss: 2.0620 - val_acc: 0.4610\n",
      "Epoch 51/100\n",
      "195/195 [==============================] - 41s 209ms/step - loss: 1.3932 - acc: 0.5133 - val_loss: 2.1388 - val_acc: 0.4494\n",
      "Epoch 52/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.3994 - acc: 0.5120 - val_loss: 2.1086 - val_acc: 0.4546\n",
      "Epoch 53/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.3891 - acc: 0.5155 - val_loss: 2.1149 - val_acc: 0.4510\n",
      "Epoch 54/100\n",
      "195/195 [==============================] - 40s 205ms/step - loss: 1.3864 - acc: 0.5149 - val_loss: 2.0801 - val_acc: 0.4586\n",
      "Epoch 55/100\n",
      "195/195 [==============================] - 42s 213ms/step - loss: 1.3862 - acc: 0.5166 - val_loss: 2.0855 - val_acc: 0.4585\n",
      "Epoch 56/100\n",
      "195/195 [==============================] - 41s 211ms/step - loss: 1.3911 - acc: 0.5134 - val_loss: 2.1417 - val_acc: 0.4512\n",
      "Epoch 57/100\n",
      "195/195 [==============================] - 41s 209ms/step - loss: 1.3921 - acc: 0.5162 - val_loss: 2.0856 - val_acc: 0.4558\n",
      "Epoch 58/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.3892 - acc: 0.5135 - val_loss: 2.0928 - val_acc: 0.4532\n",
      "Epoch 59/100\n",
      "195/195 [==============================] - 41s 209ms/step - loss: 1.3872 - acc: 0.5170 - val_loss: 2.1084 - val_acc: 0.4515\n",
      "Epoch 60/100\n",
      "195/195 [==============================] - 47s 242ms/step - loss: 1.3880 - acc: 0.5145 - val_loss: 2.0866 - val_acc: 0.4539\n",
      "Epoch 61/100\n",
      "195/195 [==============================] - 40s 206ms/step - loss: 1.3821 - acc: 0.5173 - val_loss: 2.1043 - val_acc: 0.4498\n",
      "Epoch 62/100\n",
      "195/195 [==============================] - 40s 203ms/step - loss: 1.3771 - acc: 0.5199 - val_loss: 2.0872 - val_acc: 0.4558\n",
      "Epoch 63/100\n",
      "195/195 [==============================] - 39s 201ms/step - loss: 1.3787 - acc: 0.5175 - val_loss: 2.0556 - val_acc: 0.4573\n",
      "Epoch 64/100\n",
      "195/195 [==============================] - 41s 213ms/step - loss: 1.3776 - acc: 0.5201 - val_loss: 2.0936 - val_acc: 0.4510\n",
      "Epoch 65/100\n",
      "195/195 [==============================] - 41s 212ms/step - loss: 1.3830 - acc: 0.5180 - val_loss: 2.0925 - val_acc: 0.4518\n",
      "Epoch 66/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.3771 - acc: 0.5199 - val_loss: 2.1223 - val_acc: 0.4472\n",
      "Epoch 67/100\n",
      "195/195 [==============================] - 40s 205ms/step - loss: 1.3742 - acc: 0.5190 - val_loss: 2.0625 - val_acc: 0.4586\n",
      "Epoch 68/100\n",
      "195/195 [==============================] - 39s 202ms/step - loss: 1.3740 - acc: 0.5198 - val_loss: 2.0779 - val_acc: 0.4563\n",
      "Epoch 69/100\n",
      "195/195 [==============================] - 41s 211ms/step - loss: 1.3687 - acc: 0.5210 - val_loss: 2.0826 - val_acc: 0.4562\n",
      "Epoch 70/100\n",
      "195/195 [==============================] - 43s 221ms/step - loss: 1.3773 - acc: 0.5167 - val_loss: 2.0962 - val_acc: 0.4545\n",
      "Epoch 71/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.3834 - acc: 0.5163 - val_loss: 2.0683 - val_acc: 0.4569\n",
      "Epoch 72/100\n",
      "195/195 [==============================] - 41s 212ms/step - loss: 1.3614 - acc: 0.5220 - val_loss: 2.0897 - val_acc: 0.4538\n",
      "Epoch 73/100\n",
      "195/195 [==============================] - 41s 208ms/step - loss: 1.3716 - acc: 0.5198 - val_loss: 2.0847 - val_acc: 0.4560\n",
      "Epoch 74/100\n",
      "195/195 [==============================] - 39s 201ms/step - loss: 1.3718 - acc: 0.5166 - val_loss: 2.0810 - val_acc: 0.4574\n",
      "Epoch 75/100\n",
      "195/195 [==============================] - 39s 202ms/step - loss: 1.3634 - acc: 0.5237 - val_loss: 2.0698 - val_acc: 0.4583\n",
      "Epoch 76/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.3680 - acc: 0.5212 - val_loss: 2.1152 - val_acc: 0.4527\n",
      "Epoch 77/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.3721 - acc: 0.5210 - val_loss: 2.0793 - val_acc: 0.4563\n",
      "Epoch 78/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.3740 - acc: 0.5200 - val_loss: 2.0563 - val_acc: 0.4596\n",
      "Epoch 79/100\n",
      "195/195 [==============================] - 40s 204ms/step - loss: 1.3622 - acc: 0.5228 - val_loss: 2.0810 - val_acc: 0.4560\n",
      "Epoch 80/100\n",
      "195/195 [==============================] - 40s 205ms/step - loss: 1.3675 - acc: 0.5200 - val_loss: 2.0764 - val_acc: 0.4547\n",
      "Epoch 81/100\n",
      "195/195 [==============================] - 40s 203ms/step - loss: 1.3631 - acc: 0.5244 - val_loss: 2.0693 - val_acc: 0.4594\n",
      "Epoch 82/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.3617 - acc: 0.5249 - val_loss: 2.0703 - val_acc: 0.4580\n",
      "Epoch 83/100\n",
      "195/195 [==============================] - 41s 208ms/step - loss: 1.3703 - acc: 0.5203 - val_loss: 2.0930 - val_acc: 0.4518\n",
      "Epoch 84/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.3540 - acc: 0.5263 - val_loss: 2.0675 - val_acc: 0.4538\n",
      "Epoch 85/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.3575 - acc: 0.5241 - val_loss: 2.0311 - val_acc: 0.4611\n",
      "Epoch 86/100\n",
      "195/195 [==============================] - 40s 203ms/step - loss: 1.3552 - acc: 0.5267 - val_loss: 2.0754 - val_acc: 0.4565\n",
      "Epoch 87/100\n",
      "195/195 [==============================] - 43s 222ms/step - loss: 1.3614 - acc: 0.5254 - val_loss: 2.0555 - val_acc: 0.4605\n",
      "Epoch 88/100\n",
      "195/195 [==============================] - 41s 213ms/step - loss: 1.3621 - acc: 0.5220 - val_loss: 2.0678 - val_acc: 0.4573\n",
      "Epoch 89/100\n",
      "195/195 [==============================] - 41s 209ms/step - loss: 1.3610 - acc: 0.5230 - val_loss: 2.0715 - val_acc: 0.4574\n",
      "Epoch 90/100\n",
      "195/195 [==============================] - 41s 211ms/step - loss: 1.3502 - acc: 0.5274 - val_loss: 2.0887 - val_acc: 0.4538\n",
      "Epoch 91/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.3555 - acc: 0.5251 - val_loss: 2.0710 - val_acc: 0.4529\n",
      "Epoch 92/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.3486 - acc: 0.5289 - val_loss: 2.0851 - val_acc: 0.4525\n",
      "Epoch 93/100\n",
      "195/195 [==============================] - 41s 211ms/step - loss: 1.3521 - acc: 0.5237 - val_loss: 2.0561 - val_acc: 0.4561\n",
      "Epoch 94/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.3570 - acc: 0.5236 - val_loss: 2.1212 - val_acc: 0.4486\n",
      "Epoch 95/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.3542 - acc: 0.5262 - val_loss: 2.0664 - val_acc: 0.4546\n",
      "Epoch 96/100\n",
      "195/195 [==============================] - 40s 208ms/step - loss: 1.3503 - acc: 0.5264 - val_loss: 2.0837 - val_acc: 0.4546\n",
      "Epoch 97/100\n",
      "195/195 [==============================] - 40s 207ms/step - loss: 1.3570 - acc: 0.5240 - val_loss: 2.0536 - val_acc: 0.4588\n",
      "Epoch 98/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.3473 - acc: 0.5296 - val_loss: 2.0503 - val_acc: 0.4610\n",
      "Epoch 99/100\n",
      "195/195 [==============================] - 41s 209ms/step - loss: 1.3506 - acc: 0.5292 - val_loss: 2.0611 - val_acc: 0.4586\n",
      "Epoch 100/100\n",
      "195/195 [==============================] - 41s 210ms/step - loss: 1.3519 - acc: 0.5280 - val_loss: 2.0397 - val_acc: 0.4606\n",
      "10000/10000 [==============================] - 14s 1ms/sample - loss: 2.0478 - acc: 0.4606\n",
      "Test loss: 2.0477649253845214\n",
      "Test accuracy: 0.4606\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=3e-5,decay=0.0001,beta_1=0.99,beta_2=0.999)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_history = model.fit_generator(data_generator.flow(x_train, y_train, batch_size = BATCH_SIZE),\n",
    "                                   epochs = NUM_EPOCHS,\n",
    "                                   validation_data = (x_test, y_test),\n",
    "                                    steps_per_epoch=x_train.shape[0] // BATCH_SIZE\n",
    "                                   \n",
    "                                   )\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
